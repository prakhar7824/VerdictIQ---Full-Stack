# Guide to Connect ML Model to Frontend Website

## 1. Backend Setup

### 1.1 Create a Flask/FastAPI Backend
- Install required packages:
  ```bash
  pip install flask fastapi uvicorn python-multipart
  ```

### 1.2 Create API Endpoint
- Create a new file `app.py` in your project root
- Implement an endpoint that:
  - Accepts image uploads
  - Processes the image using your model
  - Returns classification results

### 1.3 Model Integration
- Load your trained model in the backend
- Create a prediction function that:
  - Preprocesses the input image
  - Makes predictions using the model
  - Returns formatted results

## 2. Frontend Integration

### 2.1 Image Upload Component
- Create an image upload form in your frontend
- Add file type validation (accept only image files)
- Implement preview functionality

### 2.2 API Communication
- Create an API service in your frontend
- Implement functions to:
  - Send image to backend
  - Handle response
  - Display results

### 2.3 Error Handling
- Add proper error handling for:
  - Failed uploads
  - Network errors
  - Invalid file types
  - Server errors

## 3. Implementation Steps

### 3.1 Backend Implementation
1. Create a new file `app.py`:
```python
from fastapi import FastAPI, File, UploadFile
from fastapi.middleware.cors import CORSMiddleware
import numpy as np
from PIL import Image
import io
import tensorflow as tf

app = FastAPI()

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Load your model
model = tf.keras.models.load_model('path_to_your_model')

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    # Read image
    contents = await file.read()
    image = Image.open(io.BytesIO(contents))
    
    # Preprocess image
    image = image.resize((224, 224))  # Adjust size based on your model
    image = np.array(image)
    image = image / 255.0
    image = np.expand_dims(image, axis=0)
    
    # Make prediction
    prediction = model.predict(image)
    
    # Return results
    return {"prediction": prediction.tolist()}
```

### 3.2 Frontend Implementation
1. Create an API service:
```javascript
// api.js
const API_URL = 'http://localhost:8000';

export const predictImage = async (file) => {
    const formData = new FormData();
    formData.append('file', file);
    
    const response = await fetch(`${API_URL}/predict`, {
        method: 'POST',
        body: formData,
    });
    
    if (!response.ok) {
        throw new Error('Prediction failed');
    }
    
    return response.json();
};
```

2. Create an image upload component:
```javascript
// ImageUpload.js
import React, { useState } from 'react';
import { predictImage } from './api';

function ImageUpload() {
    const [file, setFile] = useState(null);
    const [preview, setPreview] = useState(null);
    const [prediction, setPrediction] = useState(null);
    const [loading, setLoading] = useState(false);
    const [error, setError] = useState(null);

    const handleFileChange = (e) => {
        const selectedFile = e.target.files[0];
        if (selectedFile) {
            setFile(selectedFile);
            setPreview(URL.createObjectURL(selectedFile));
        }
    };

    const handleSubmit = async (e) => {
        e.preventDefault();
        if (!file) return;

        setLoading(true);
        setError(null);

        try {
            const result = await predictImage(file);
            setPrediction(result.prediction);
        } catch (err) {
            setError('Failed to process image');
        } finally {
            setLoading(false);
        }
    };

    return (
        <div>
            <form onSubmit={handleSubmit}>
                <input
                    type="file"
                    accept="image/*"
                    onChange={handleFileChange}
                />
                <button type="submit" disabled={!file || loading}>
                    {loading ? 'Processing...' : 'Predict'}
                </button>
            </form>
            
            {preview && (
                <div>
                    <img src={preview} alt="Preview" style={{ maxWidth: '300px' }} />
                </div>
            )}
            
            {prediction && (
                <div>
                    <h3>Prediction Results:</h3>
                    <pre>{JSON.stringify(prediction, null, 2)}</pre>
                </div>
            )}
            
            {error && <div style={{ color: 'red' }}>{error}</div>}
        </div>
    );
}

export default ImageUpload;
```

## 4. Testing and Deployment

### 4.1 Local Testing
1. Start the backend server:
```bash
uvicorn app:app --reload
```

2. Test the API using Postman or similar tool
3. Test the frontend integration locally

### 4.2 Deployment
1. Deploy backend to a cloud service (AWS, GCP, Heroku)
2. Update frontend API URL to point to deployed backend
3. Deploy frontend to your hosting service

## 5. Security Considerations

1. Add file size limits
2. Implement rate limiting
3. Add authentication if needed
4. Validate file types on both frontend and backend
5. Use HTTPS in production

## 6. Performance Optimization

1. Implement image compression before upload
2. Add loading states and progress indicators
3. Cache predictions if needed
4. Optimize model size for production

## 7. Monitoring and Maintenance

1. Add logging for predictions
2. Monitor API usage
3. Set up error tracking
4. Regular model updates
5. Performance monitoring

## 8. Additional Features (Optional)

1. Batch processing
2. Multiple model support
3. Confidence scores
4. Historical predictions
5. Export functionality 